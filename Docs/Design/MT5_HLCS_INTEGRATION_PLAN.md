# ğŸ§© MT5_HLCS_INTEGRATION_PLAN â€” Plan de IntegraciÃ³n de Hyper Latin Cube Sampling (HLCS)

**Fecha de creaciÃ³n:** 2025-11-11  
**VersiÃ³n:** 1.0  
**Autor:** Sistema IA â€” Proyecto MT5_BOT

---

## ğŸ¯ Objetivo
Definir la estrategia de integraciÃ³n del mÃ©todo **Hyper Latin Cube Sampling (HLCS)** dentro de la arquitectura modular de MT5_BOT, para la **Fase 2** del proyecto.

El HLCS permitirÃ¡ realizar **muestreos multidimensionales eficientes** de hiperparÃ¡metros de modelos ML, maximizando cobertura y reduciendo redundancia en comparaciÃ³n con mÃ©todos aleatorios o deterministas tradicionales.

---

## ğŸ§  Rol del HLCS en el proyecto

| Componente | FunciÃ³n |
|-------------|----------|
| `ml/optimization/hlcs_sampler.py` | ImplementarÃ¡ el algoritmo HLCS para generar combinaciones de hiperparÃ¡metros. |
| `ml/optimization/optuna_bridge.py` | PermitirÃ¡ comparar HLCS vs Optuna en tÃ©rminos de eficiencia y convergencia. |
| `ml/training/trainer.py` | IntegrarÃ¡ HLCS como mÃ©todo de exploraciÃ³n previo a entrenamientos masivos. |

---

## âš™ï¸ Arquitectura propuesta

```
ml/
â”œâ”€ optimization/
â”‚   â”œâ”€ hlcs_sampler.py       â† implementaciÃ³n base del mÃ©todo HLCS
â”‚   â”œâ”€ optuna_bridge.py      â† integraciÃ³n con frameworks de optimizaciÃ³n adaptativa
â”‚   â”œâ”€ random_search.py
â”‚   â”œâ”€ bayesian_optim.py
â”‚   â””â”€ __init__.py
â””â”€ training/
    â”œâ”€ trainer.py            â† integraciÃ³n del sampler HLCS en los ciclos de entrenamiento
    â””â”€ __init__.py
```

---

## ğŸ“Š Flujo operativo

1. Definir los rangos de hiperparÃ¡metros (ejemplo: learning_rate, n_estimators, max_depth).  
2. Generar combinaciones usando HLCS:  
   ```python
   from ml.optimization.hlcs_sampler import hlcs_generate_samples

   params = {
       "learning_rate": (0.001, 0.2),
       "n_estimators": (50, 500),
       "max_depth": (3, 12)
   }
   samples = hlcs_generate_samples(params, n_samples=50)
   ```
3. Pasar las muestras al motor de entrenamiento (`trainer.py`) para evaluaciÃ³n cruzada.  
4. Registrar los resultados en `mlflow` o `Docs/Logs/opt_results/`.  

---

## ğŸ§© Beneficios esperados
- Cobertura uniforme del espacio de bÃºsqueda.
- ReducciÃ³n del nÃºmero de pruebas necesarias.
- Mejor estabilidad y reproducibilidad.
- IntegraciÃ³n fluida con mÃ³dulos ya existentes.

---

## ğŸ”® PrÃ³ximos pasos
1. Implementar `hlcs_sampler.py` en la **Fase 2** del desarrollo.  
2. Probar comparativas con `random_search` y `optuna`.  
3. Documentar mÃ©tricas de eficiencia y convergencia.  

---

ğŸ“˜ *Este plan se vincula directamente con la hoja de ruta tÃ©cnica de la Fase 2 y debe considerarse parte integral del mÃ³dulo `ml/optimization`.*
